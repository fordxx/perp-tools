#!/usr/bin/env python3
"""
Run All Performance Benchmarks
è¿è¡Œæ‰€æœ‰æ€§èƒ½æµ‹è¯•
"""
import sys
import subprocess
from pathlib import Path
from datetime import datetime
import argparse


# æµ‹è¯•æ–‡ä»¶åˆ—è¡¨
TEST_FILES = [
    "test_market_data.py",
    "test_arbitrage_scanner.py",
    "test_risk_manager.py",
]


def run_test(test_file: Path, verbose: bool = False) -> bool:
    """
    è¿è¡Œå•ä¸ªæµ‹è¯•æ–‡ä»¶

    Args:
        test_file: æµ‹è¯•æ–‡ä»¶è·¯å¾„
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†è¾“å‡º

    Returns:
        æµ‹è¯•æ˜¯å¦é€šè¿‡
    """
    print(f"\n{'=' * 80}")
    print(f"Running: {test_file.name}")
    print(f"{'=' * 80}\n")

    try:
        result = subprocess.run(
            [sys.executable, str(test_file)],
            cwd=test_file.parent,
            capture_output=not verbose,
            text=True,
            timeout=600,  # 10åˆ†é’Ÿè¶…æ—¶
        )

        if result.returncode == 0:
            print(f"âœ… {test_file.name} PASSED")
            if not verbose and result.stdout:
                # åªæ˜¾ç¤ºå…³é”®ä¿¡æ¯
                lines = result.stdout.split("\n")
                for line in lines:
                    if "PASS" in line or "FAIL" in line or "Report:" in line:
                        print(f"   {line}")
            return True
        else:
            print(f"âŒ {test_file.name} FAILED")
            if result.stdout:
                print("STDOUT:")
                print(result.stdout)
            if result.stderr:
                print("STDERR:")
                print(result.stderr)
            return False

    except subprocess.TimeoutExpired:
        print(f"â±ï¸  {test_file.name} TIMEOUT (>10 minutes)")
        return False
    except Exception as e:
        print(f"ğŸ’¥ {test_file.name} ERROR: {e}")
        return False


def main():
    parser = argparse.ArgumentParser(description="Run all performance benchmarks")
    parser.add_argument(
        "-v", "--verbose",
        action="store_true",
        help="Show detailed test output"
    )
    parser.add_argument(
        "--filter",
        type=str,
        help="Only run tests matching this pattern"
    )
    args = parser.parse_args()

    print("=" * 80)
    print("PerpBot V2 Performance Benchmark Suite")
    print("=" * 80)
    print(f"Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()

    # ç¡®å®šæµ‹è¯•ç›®å½•
    test_dir = Path(__file__).parent

    # è¿‡æ»¤æµ‹è¯•æ–‡ä»¶
    test_files = TEST_FILES
    if args.filter:
        test_files = [f for f in test_files if args.filter in f]
        print(f"Filtered tests: {test_files}")
        print()

    # è¿è¡Œæµ‹è¯•
    results = {}
    for test_file_name in test_files:
        test_file = test_dir / test_file_name
        if not test_file.exists():
            print(f"âš ï¸  Test file not found: {test_file}")
            results[test_file_name] = False
            continue

        passed = run_test(test_file, verbose=args.verbose)
        results[test_file_name] = passed

    # æ±‡æ€»ç»“æœ
    print("\n" + "=" * 80)
    print("Test Summary")
    print("=" * 80)

    passed_count = sum(1 for p in results.values() if p)
    failed_count = len(results) - passed_count

    for test_name, passed in results.items():
        status = "âœ… PASS" if passed else "âŒ FAIL"
        print(f"{status:10} | {test_name}")

    print()
    print(f"Total:  {len(results)}")
    print(f"Passed: {passed_count}")
    print(f"Failed: {failed_count}")

    if failed_count == 0:
        print("\nğŸ‰ All performance tests PASSED!")
        return 0
    else:
        print(f"\nğŸ’” {failed_count} test(s) FAILED")
        return 1


if __name__ == "__main__":
    sys.exit(main())
